{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c52a8900",
   "metadata": {},
   "source": [
    "   # End-to-End Diabetes Machine Learning                                    Pipeline I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a085a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Exploratory Data Analysis\n",
    "# 2. Data Preprocessing & Feature Engineering\n",
    "# 3. Base Models\n",
    "# 4. Automated Hyperparameter Optimization\n",
    "# 5. Stacking & Ensemble Learning\n",
    "# 6. Prediction for a New Observation\n",
    "# 7. Pipeline Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e57c6bc",
   "metadata": {},
   "source": [
    "resarch kısmında çeşitli geliştirmeler yapacağız, kararlar vereceğiz.\n",
    "pipelinekısmında ise temel modellerin başarı skorlarını göreceğiz.\n",
    "\n",
    "genellikle projelerde 2 dosya olur. biri çalışma dosyasıdır (research). Diğeri ise pipeline. pipelineda çalışma dosyasında olanlar scriptlere çevrildiği yerdir. son nihai hali alır. burada veri görselleştiem adımları, işte şunlara bakayım gözlemleyeyim gibi adımlar pipeline da olmaz. araştırma gözlemleme kısmı resarch dosyasında yapılır.pipeline da sadece fonksiyonalar kodlar kalır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0449e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb53656",
   "metadata": {},
   "source": [
    "## 1. Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d295b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_df(dataframe, head=5):\n",
    "    print(\"##################### Shape #####################\")\n",
    "    print(dataframe.shape)\n",
    "    print(\"##################### Types #####################\")\n",
    "    print(dataframe.dtypes)\n",
    "    print(\"##################### Head #####################\")\n",
    "    print(dataframe.head(head))\n",
    "    print(\"##################### Tail #####################\")\n",
    "    print(dataframe.tail(head))\n",
    "    print(\"##################### NA #####################\")\n",
    "    print(dataframe.isnull().sum())\n",
    "    print(\"##################### Quantiles #####################\")\n",
    "    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9be703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_summary(dataframe, col_name, plot=False):\n",
    "    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n",
    "                        \"Ratio\": 100 * dataframe[col_name].value_counts() / len(dataframe)}))\n",
    "    print(\"##########################################\")\n",
    "    if plot:\n",
    "        sns.countplot(x=dataframe[col_name], data=dataframe)\n",
    "        plt.show(block=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b57888",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def num_summary(dataframe, numerical_col, plot=False):\n",
    "    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n",
    "    print(dataframe[numerical_col].describe(quantiles).T)\n",
    "    \n",
    "    if plot:\n",
    "        dataframe[numerical_col].hist(bins=20)\n",
    "        plt.xlabel(numerical_col)\n",
    "        plt.title(numerical_col)\n",
    "        plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed83f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_summary_with_num(dataframe, target, numerical_col):\n",
    "    print(dataframe.groupby(target).agg({numerical_col: \"mean\"}), end=\"\\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56be1f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_summary_with_cat(dataframe, target, categorical_col):\n",
    "    print(pd.DataFrame({\"TARGET_MEAN\": dataframe.groupby(categorical_col)[target].mean()}), end=\"\\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b1a4d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(df, cols):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(10, 8)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    fig = sns.heatmap(df[cols].corr(), annot=True, linewidths=0.5, annot_kws={'size': 12}, linecolor='w', cmap='RdBu')\n",
    "    plt.show(block=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3a6a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
    "    \"\"\"\n",
    "\n",
    "    Veri setindeki kategorik, numerik ve kategorik fakat kardinal değişkenlerin isimlerini verir.\n",
    "    Not: Kategorik değişkenlerin içerisine numerik görünümlü kategorik değişkenler de dahildir.\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        dataframe: dataframe\n",
    "                Değişken isimleri alınmak istenilen dataframe\n",
    "        cat_th: int, optional\n",
    "                numerik fakat kategorik olan değişkenler için sınıf eşik değeri\n",
    "        car_th: int, optinal\n",
    "                kategorik fakat kardinal değişkenler için sınıf eşik değeri\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "        cat_cols: list\n",
    "                Kategorik değişken listesi\n",
    "        num_cols: listMİN\n",
    "                Numerik değişken listesi\n",
    "        cat_but_car: list\n",
    "                Kategorik görünümlü kardinal değişken listesi\n",
    "\n",
    "    Examples\n",
    "    ------\n",
    "        import seaborn as sns\n",
    "        df = sns.load_dataset(\"iris\")\n",
    "        print(grab_col_names(df))\n",
    "\n",
    "\n",
    "    Notes\n",
    "    ------\n",
    "        cat_cols + num_cols + cat_but_car = toplam değişken sayısı\n",
    "        num_but_cat cat_cols'un içerisinde.\n",
    "        Return olan 3 liste toplamı toplam değişken sayısına eşittir: cat_cols + num_cols + cat_but_car = değişken sayısı\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # cat_cols, cat_but_car\n",
    "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n",
    "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n",
    "                   dataframe[col].dtypes != \"O\"]\n",
    "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n",
    "                   dataframe[col].dtypes == \"O\"]\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "\n",
    "    # num_cols\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
    "\n",
    "    # print(f\"Observations: {dataframe.shape[0]}\")\n",
    "    # print(f\"Variables: {dataframe.shape[1]}\")\n",
    "    # print(f'cat_cols: {len(cat_cols)}')\n",
    "    # print(f'num_cols: {len(num_cols)}')\n",
    "    # print(f'cat_but_car: {len(cat_but_car)}')\n",
    "    # print(f'num_but_cat: {len(num_but_cat)}')\n",
    "    return cat_cols, num_cols, cat_but_car"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c2ace3",
   "metadata": {},
   "source": [
    "buraya kadar yazdığımız fonksiyonları pipeline kısmına almayacağız. grab_col_names hariç."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e3fd32e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/esman/OneDrive/Masaüstü/MachineLearning_datasets/diabetes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df  \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/esman/OneDrive/Masaüstü/MachineLearning_datasets/diabetes.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/esman/OneDrive/Masaüstü/MachineLearning_datasets/diabetes.csv'"
     ]
    }
   ],
   "source": [
    "df  = pd.read_csv(\"C:/Users/esman/OneDrive/Masaüstü/MachineLearning_datasets/diabetes.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0226d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eksik değer 0 gözüküyor. bu imkansız. şuan bunu görmezden gelicez. \n",
    "check_df(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed2cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Değişken türlerinin ayrıştırılması\n",
    "cat_cols, num_cols, cat_but_car = grab_col_names(df, cat_th=5, car_th=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf5678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kategorik değişkenlerin incelenmesi\n",
    "for col in cat_cols:\n",
    "    cat_summary(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b531cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sayısal değişkenlerin incelenmesi\n",
    "df[num_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2678f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sayısal değerleir görselleştirmek istediğimde\n",
    "for col in num_cols:\n",
    "    num_summary(df, col, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e68c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sayısal değişkenkerin birbirleri ile korelasyonu\n",
    "correlation_matrix(df, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c024d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target ile sayısal değişkenlerin incelemesi\n",
    "for col in num_cols:\n",
    "    target_summary_with_num(df, \"Outcome\", col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240d6169",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing & Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa99ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_thresholds(dataframe, col_name, q1=0.25, q3=0.75):\n",
    "    quartile1 = dataframe[col_name].quantile(q1)\n",
    "    quartile3 = dataframe[col_name].quantile(q3)\n",
    "    interquantile_range = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * interquantile_range\n",
    "    low_limit = quartile1 - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021283ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_thresholds(dataframe, variable):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n",
    "    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n",
    "    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outlier(dataframe, col_name, q1=0.25, q3=0.75):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name, q1, q3)\n",
    "    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c9a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n",
    "    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4da149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Değişken isimleri büyütmek\n",
    "df.columns = [col.upper() for col in df.columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1d1d02",
   "metadata": {},
   "source": [
    "                          Yeni değişkenler üretme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0ecd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glucose verisini kullanarak new_glucose_cat değişkeni oluşturduk.\n",
    "#yeni glucose değişkeni oluştu diye gidip glucose değerini silme.\n",
    "#yeni oluşturudğun değişken anlamsız da olabilir. \n",
    "#modellleme basamağına kadar bekle. glucose silme.\n",
    "df['NEW_GLUCOSE_CAT'] = pd.cut(x=df['GLUCOSE'], bins=[-1, 139, 200], labels=[\"normal\", \"prediabetes\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228a8bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "df.loc[(df['AGE'] < 35), \"NEW_AGE_CAT\"] = 'young'\n",
    "df.loc[(df['AGE'] >= 35) & (df['AGE'] <= 55), \"NEW_AGE_CAT\"] = 'middleage'\n",
    "df.loc[(df['AGE'] > 55), \"NEW_AGE_CAT\"] = 'old'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3637013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI\n",
    "df['NEW_BMI_RANGE'] = pd.cut(x=df['BMI'], bins=[-1, 18.5, 24.9, 29.9, 100],\n",
    "                             labels=[\"underweight\", \"healty\", \"overweight\", \"obese\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f9d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BloodPressure\n",
    "df['NEW_BLOODPRESSURE'] = pd.cut(x=df['BLOODPRESSURE'], bins=[-1, 79, 89, 123], labels=[\"normal\", \"hs1\", \"hs2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a42838",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols, num_cols, cat_but_car = grab_col_names(df, cat_th=5, car_th=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f42609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in cat_cols:\n",
    "    cat_summary(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e9bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    target_summary_with_cat(df, \"OUTCOME\", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4589221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outcome bağımlı değişkenim bunu cat_cols dan çıkarıyorum.\n",
    "cat_cols = [col for col in cat_cols if \"OUTCOME\" not in col]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a57c3",
   "metadata": {},
   "source": [
    "Makine öğrenmesi uygulayabilmek için;\n",
    "- değişkenleri ya binary encode edeceğiz.\n",
    "- ya da değişkenleri sayısal formda ifade etmelisin. \n",
    "\n",
    "örneğin:\n",
    "- oluşturduğun sayısal değişkenleri 1-2-3 gibi temsil edip olduğu gibi bırakabilirsin. bu sınıflar zaten büüyklük küçüklük kavramını içinde taşıyacak. böylece sayısal değişkenleri label encoding ile dönüştürebiliriz bu bir tercih.\n",
    "- başka bir tercih olarak da bu değişkenleri one hot encoderdan geçirebiliriz. one hot encoderdan geçirilince bir değişkendeki sınıf sayısı kadar yeni kategorik değişken oluyor olacak. böylece bunlar binary encode edilmiş olacak.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dc5503",
   "metadata": {},
   "source": [
    "drop_first=True yapılır ki 2 sınıflı olan kategorik değişkenlerin ilk sınıfını dışarıda bırakır. böylece dummy değişkenı tuzağından kurtulmuş oluruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoderi label encoder olarak da kullanabilmek için drop_first=true\n",
    "\n",
    "df = one_hot_encoder(df, cat_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f06883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [col.upper() for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0283d61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Son güncel değişken türlerimi tutuyorum. çünkü bir sürü değişken türettim.\n",
    "cat_cols, num_cols, cat_but_car = grab_col_names(df, cat_th=5, car_th=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f6968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_cols bir daha güncelle.\n",
    "cat_cols = [col for col in cat_cols if \"OUTCOME\" not in col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d2e68",
   "metadata": {},
   "source": [
    "iqr hesabındaki q1=0.05 , q3=0.95 olarak giriyorum. iqr iyidir ama çok değişkenli etkiyi göz önünde bulunduramaz. bu yüzden aşırı aykırı olanlara ucundan dokunuyorum sadece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a95ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aykırı değerleri değerlendir.\n",
    "for col in num_cols:\n",
    "    print(col, check_outlier(df, col, 0.05, 0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589eac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_with_thresholds(df, \"INSULIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc563cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    print(col, check_outlier(df, col, 0.05, 0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe7dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standartlaştırma\n",
    "#x_scaled numerik değişnkenlerin standartlaştırılmış halini nparray olarak tutuyor.\n",
    "X_scaled = StandardScaler().fit_transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe80883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_scaled dataframe atıyorum.\n",
    "df[num_cols] = pd.DataFrame(X_scaled, columns=df[num_cols].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09c1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"OUTCOME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a19964",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"OUTCOME\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d3b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df(X)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d229a71e",
   "metadata": {},
   "source": [
    "ŞU ANA KADAR YAPTIĞIMIZ İŞLEMLERİ FONKSİYONLAŞTIRALIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ace175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diabetes_data_prep(dataframe):\n",
    "    dataframe.columns = [col.upper() for col in dataframe.columns]\n",
    "\n",
    "    # Glucose\n",
    "    dataframe['NEW_GLUCOSE_CAT'] = pd.cut(x=dataframe['GLUCOSE'], bins=[-1, 139, 200], labels=[\"normal\", \"prediabetes\"])\n",
    "\n",
    "    # Age\n",
    "    dataframe.loc[(dataframe['AGE'] < 35), \"NEW_AGE_CAT\"] = 'young'\n",
    "    dataframe.loc[(dataframe['AGE'] >= 35) & (dataframe['AGE'] <= 55), \"NEW_AGE_CAT\"] = 'middleage'\n",
    "    dataframe.loc[(dataframe['AGE'] > 55), \"NEW_AGE_CAT\"] = 'old'\n",
    "\n",
    "    # BMI\n",
    "    dataframe['NEW_BMI_RANGE'] = pd.cut(x=dataframe['BMI'], bins=[-1, 18.5, 24.9, 29.9, 100],\n",
    "                                        labels=[\"underweight\", \"healty\", \"overweight\", \"obese\"])\n",
    "\n",
    "    # BloodPressure\n",
    "    dataframe['NEW_BLOODPRESSURE'] = pd.cut(x=dataframe['BLOODPRESSURE'], bins=[-1, 79, 89, 123],\n",
    "                                            labels=[\"normal\", \"hs1\", \"hs2\"])\n",
    "\n",
    "    cat_cols, num_cols, cat_but_car = grab_col_names(dataframe, cat_th=5, car_th=20)\n",
    "\n",
    "    cat_cols = [col for col in cat_cols if \"OUTCOME\" not in col]\n",
    "\n",
    "    df = one_hot_encoder(dataframe, cat_cols, drop_first=True)\n",
    "\n",
    "    df.columns = [col.upper() for col in df.columns]\n",
    "\n",
    "    cat_cols, num_cols, cat_but_car = grab_col_names(df, cat_th=5, car_th=20)\n",
    "\n",
    "    cat_cols = [col for col in cat_cols if \"OUTCOME\" not in col]\n",
    "\n",
    "    replace_with_thresholds(df, \"INSULIN\")\n",
    "\n",
    "    X_scaled = StandardScaler().fit_transform(df[num_cols])\n",
    "    df[num_cols] = pd.DataFrame(X_scaled, columns=df[num_cols].columns)\n",
    "\n",
    "    y = df[\"OUTCOME\"]\n",
    "    X = df.drop([\"OUTCOME\"], axis=1)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659d703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#veri setimin ilk halini gözlemliyorum.\n",
    "df  = pd.read_csv(\"C:/Users/esman/OneDrive/Masaüstü/MachineLearning_datasets/diabetes.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3245d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22437930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yazdığım fonksiyonu çağrıyorum.\n",
    "X, y = diabetes_data_prep(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bd454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kontrol işlemini gerçekleştir.\n",
    "check_df(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f700133",
   "metadata": {},
   "source": [
    "# 3. BASE MODELS\n",
    "Bu aşama pipelineda da yer alabilir. ancak research kısmında yer alması daha doğru.\n",
    "temel bazı modellere bakılır. modellerden probleme en uygun olan 1 ya da birden fazla model seçilir. bu modellerin üzerinde hiperparametre optimizasyonları gerçekleştiriliyor olunur.\n",
    "genellikle LİGHTGBM en iyi model olur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331debee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temel modellerdeki hatalara bakmka için bir fonksiyonn yazıyorum.\n",
    "def base_models(X, y, scoring=\"roc_auc\"):\n",
    "    print(\"Base Models....\")\n",
    "    #sol tarafdakiler kendi isimlendirmemiz.\n",
    "    classifiers = [('LR', LogisticRegression()),\n",
    "                   ('KNN', KNeighborsClassifier()),\n",
    "                   (\"SVC\", SVC()),\n",
    "                   (\"CART\", DecisionTreeClassifier()),\n",
    "                   (\"RF\", RandomForestClassifier()),\n",
    "                   ('Adaboost', AdaBoostClassifier()),\n",
    "                   ('GBM', GradientBoostingClassifier()),\n",
    "                   ('XGBoost', XGBClassifier(use_label_encoder=False, eval_metric='logloss')),\n",
    "                   ('LightGBM', LGBMClassifier()),\n",
    "                   #catboost okumak zor diye commentledik ama bunuda aç.\n",
    "                   # ('CatBoost', CatBoostClassifier(verbose=False))\n",
    "                   ]\n",
    "\n",
    "    for name, classifier in classifiers:\n",
    "        #3 katlı cross-validation geçir.\n",
    "        cv_results = cross_validate(classifier, X, y, cv=3, scoring=scoring)\n",
    "        print(f\"{scoring}: {round(cv_results['test_score'].mean(), 4)} ({name}) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b19780",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models(X, y, scoring=\"accuracy\")\n",
    "#burada en başrılısı LR gözüküyor. ancak gelişmiş modellerle ilgili işlem yapmadığımız için bunun doğruluğundan çok da emin olamıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec90d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scoring bölümünü değiştir. modellerin accuracy değerleirni getirsin.\n",
    "#accuracy değerlerine göre başarıyı değerlendir.\n",
    "base_models(X, y, scoring=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bbb94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f2 score göre başarıyı değerlendir.\n",
    "base_models(X, y, scoring=\"f1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce82cfc",
   "metadata": {},
   "source": [
    "# 4. Automated Hyperparameter Optimization\n",
    "Birden fazla modelin birden fazla arama görevini fonksiyon tanımlayarak otomatik bir şekilde gerçekleştireceğiz.\n",
    "arama yapmak istediğim hiperparametre setlerini giriyorum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dfd829",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\"n_neighbors\": range(2, 50)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b99c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_params = {'max_depth': range(1, 20),\n",
    "               \"min_samples_split\": range(2, 30)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6aa3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\"max_depth\": [8, 15, None],\n",
    "             \"max_features\": [5, 7, \"auto\"],\n",
    "             \"min_samples_split\": [15, 20],\n",
    "             \"n_estimators\": [200, 300]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_params = {\"learning_rate\": [0.1, 0.01],\n",
    "                  \"max_depth\": [5, 8],\n",
    "                  \"n_estimators\": [100, 200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee147d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_params = {\"learning_rate\": [0.01, 0.1],\n",
    "                   \"n_estimators\": [300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeller ve aranacak olan hiperparametreler bir arada olsun istiyorum.\n",
    "classifiers = [('KNN', KNeighborsClassifier(), knn_params),\n",
    "               (\"CART\", DecisionTreeClassifier(), cart_params),\n",
    "               (\"RF\", RandomForestClassifier(), rf_params),\n",
    "               ('XGBoost', XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgboost_params),\n",
    "               ('LightGBM', LGBMClassifier(), lightgbm_params)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf4e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_optimization(X, y, cv=3, scoring=\"roc_auc\"):\n",
    "    print(\"Hyperparameter Optimization....\")\n",
    "    best_models = {}\n",
    "    for name, classifier, params in classifiers:\n",
    "        print(f\"########## {name} ##########\")\n",
    "        cv_results = cross_validate(classifier, X, y, cv=cv, scoring=scoring)\n",
    "        \n",
    "        #bir modelin cv den önceki hatası\n",
    "        print(f\"{scoring} (Before): {round(cv_results['test_score'].mean(), 4)}\")\n",
    "       \n",
    "        #hiperparametre değerlerini bul\n",
    "        gs_best = GridSearchCV(classifier, params, cv=cv, n_jobs=-1, verbose=False).fit(X, y)\n",
    "        final_model = classifier.set_params(**gs_best.best_params_)\n",
    "\n",
    "        cv_results = cross_validate(final_model, X, y, cv=cv, scoring=scoring)\n",
    "        \n",
    "        #modelin cv den sonraki hatası\n",
    "        print(f\"{scoring} (After): {round(cv_results['test_score'].mean(), 4)}\")\n",
    "        \n",
    "        #raporlama kısmı\n",
    "        print(f\"{name} best params: {gs_best.best_params_}\", end=\"\\n\\n\")\n",
    "        \n",
    "        best_models[name] = final_model\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b60e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = hyperparameter_optimization(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1861f7d3",
   "metadata": {},
   "source": [
    "# 5. Stacking & Ensemble Learning\n",
    "Temeli birden fazla modeli bir arada kullanmaya dayanmaktadır.\n",
    "Stacking&Ensemble Learning: topluluk öğrenme yöntemi kapsamındadır. birden fazla algortmanın bir araya gelerek bir işi yapmasına denir.\n",
    "meta learning veya voiting  de denir.\n",
    "birden fazla model bir iş için tahminde bulunur. ardından bunlar bir araya getirilir. ve bir gözlem birimi geldiğinde bunların hepsi birlikte o gözlme birimini tahmin etmeye çalışır.\n",
    "böylece tahmin performansının artmasını bekleriz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0cf1f5",
   "metadata": {},
   "source": [
    "voting_classifier dokümantasyonuna git. \n",
    "    - Soft voiting --> sınıf gerçekleşme olasılıkları üzerinden bir oylama yapılır. en sık tekrar eden tahmin sınıfı hangisiyse onun sonucunu tahmin diye verir.\n",
    "    - Hard voiting --> ön tanımlı değeri hard. en fazla oyu olan sınıfı ifade eder. ve bu sınıfı tahmin eder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c90f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def voting_classifier(best_models, X, y):\n",
    "    #fonksiyonun çalıştığını görmek için:\n",
    "    print(\"Voting Classifier...\")\n",
    "    #daha önce oluşturduğumuz best model içinden modelleri çağrıyorum.\n",
    "    voting_clf = VotingClassifier(estimators=[('KNN', best_models[\"KNN\"]),\n",
    "                                              ('RF', best_models[\"RF\"]),\n",
    "                                              ('LightGBM', best_models[\"LightGBM\"])],\n",
    "                                  voting='soft').fit(X, y)\n",
    "\n",
    "    cv_results = cross_validate(voting_clf, X, y, cv=3, scoring=[\"accuracy\", \"f1\", \"roc_auc\"])\n",
    "    print(f\"Accuracy: {cv_results['test_accuracy'].mean()}\")\n",
    "    print(f\"F1Score: {cv_results['test_f1'].mean()}\")\n",
    "    print(f\"ROC_AUC: {cv_results['test_roc_auc'].mean()}\")\n",
    "    return voting_clf\n",
    "\n",
    "voting_clf = voting_classifier(best_models, X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9945cd",
   "metadata": {},
   "source": [
    "# 6. Prediction for a New Observation\n",
    "voiting classifier kullanarak tahmin işlemimizi yapalım.\n",
    "veri seti içinden rastgele bir gözlem birimi seçip bunu tahmin edeceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c059cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#değişkenlerimiz. veri ön işleme işlemlerinden sonraki son halimiz X DİR. Bu nednele x.columns.\n",
    "X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4bef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rastgele kullanıcı seç\n",
    "random_user = X.sample(1, random_state=45)\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f78c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bu kullanıcı için diyabet tahminleri\n",
    "voting_clf.predict(random_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712e390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kullandığın modeli kaydet\n",
    "joblib.dump(voting_clf, \"voting_clf2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c228948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kaydettiğin model çalışıyor mu bunu test etmek için modeli yükle:\n",
    "new_model = joblib.load(\"voting_clf2.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c666c3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yüklediğin modelle tahmin işlemlerini gerçekleştir.\n",
    "new_model.predict(random_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20557ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b196c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28071502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6997c18a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
